{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12 Building Parsimonious Models - [25 points] - Solutions\n",
    "\n",
    "\n",
    "## <u>Case Study</u>: Creating an Classifer Model that will Accurately Predict whether an Instagram Account is Fake or Real *with New Data*\n",
    "\n",
    "We will revisit the fake_insta_cleaned.csv dataset one more time with a different research goal in mind now. In lab 11, we assess how well our model would be at preciting fake accounts in the just the *dataset that we were given*. Now, we would like to build a model that will make accurate predictions *for new datasets*.\n",
    "\n",
    "We will build a logistic regression model that predicts the probability that an account is fake, using the following explanatory variables.\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preliminaries\n",
    "### 1.1 [0.5 pt] Read the fake_insta_cleaned.csv into a dataframe called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_insta_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0               yes                        1                     30   \n",
       "1               yes                        5                     64   \n",
       "2               yes                        2                     82   \n",
       "3               yes                        1                     76   \n",
       "4               yes                        1                      0   \n",
       "\n",
       "   number_of_posts  number_of_followers  number_of_follows account_type  \n",
       "0               35                  488                604         real  \n",
       "1                3                   35                  6         real  \n",
       "2              319                  328                668         real  \n",
       "3                6                  225                356         real  \n",
       "4                6                  362                424         real  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. [0.5 pt] Next, create a new variable y in df that is equal to 1 when the the account is fake and that is equal to 0 when the account is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0               yes                        1                     30   \n",
       "1               yes                        5                     64   \n",
       "2               yes                        2                     82   \n",
       "3               yes                        1                     76   \n",
       "4               yes                        1                      0   \n",
       "\n",
       "   number_of_posts  number_of_followers  number_of_follows account_type  y  \n",
       "0               35                  488                604         real  0  \n",
       "1                3                   35                  6         real  0  \n",
       "2              319                  328                668         real  0  \n",
       "3                6                  225                356         real  0  \n",
       "4                6                  362                424         real  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['account_type'].map({'fake': 1, 'real' : 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Test Data\n",
    "\n",
    "First, we want to create a training dataset to train the dataset and a test dataset to test the model's performance.\n",
    "\n",
    "### 2.1. [2 pts] First, create a training dataset and a test dataset where:\n",
    "* the training dataset is comprised of a random sample of 85% of the rows in our dataframe,\n",
    "* the test dataset is comprised of the remaining 15% of rows in the dataframe, and\n",
    "* we use a random state of 456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(df,test_size = .15, random_state = 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482142857142857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15178571428571427"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Model\n",
    "\n",
    "Next, we would like for our 'full model' to predict the probability that an account is fake, using ALL of the following available explanatory variables.\n",
    "* the number of accounts someone *follows*\n",
    "* number of *followers*\n",
    "* number of posts\n",
    "* number of words in name\n",
    "* number of characters in the bio\n",
    "* whether they have a profile picture or not\n",
    "\n",
    "### 3.1. [1 pt] Fit the full model with all six of these explanatory variables using just your *training dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.122645\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    88</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 11 May 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8227</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:25:27</td>     <th>  Log-Likelihood:    </th> <td> -11.651</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.015e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  106.9158</td> <td>  1.2e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td> -101.7707</td> <td>  1.2e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-2.35e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0098</td> <td>    0.003</td> <td>    3.168</td> <td> 0.002</td> <td>    0.004</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0299</td> <td>    0.010</td> <td>   -3.107</td> <td> 0.002</td> <td>   -0.049</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_posts</th>          <td>    0.0084</td> <td>    0.009</td> <td>    0.973</td> <td> 0.331</td> <td>   -0.009</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.4222</td> <td>    0.621</td> <td>   -2.290</td> <td> 0.022</td> <td>   -2.640</td> <td>   -0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1171</td> <td>    0.053</td> <td>   -2.201</td> <td> 0.028</td> <td>   -0.221</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.52 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       88\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Tue, 11 May 2021   Pseudo R-squ.:                  0.8227\n",
       "Time:                        00:25:27   Log-Likelihood:                -11.651\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.015e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  106.9158    1.2e+05      0.001      0.999   -2.35e+05    2.35e+05\n",
       "has_a_profile_pic[T.yes]  -101.7707    1.2e+05     -0.001      0.999   -2.35e+05    2.35e+05\n",
       "number_of_follows            0.0098      0.003      3.168      0.002       0.004       0.016\n",
       "number_of_followers         -0.0299      0.010     -3.107      0.002      -0.049      -0.011\n",
       "number_of_posts              0.0084      0.009      0.973      0.331      -0.009       0.025\n",
       "number_of_words_in_name     -1.4222      0.621     -2.290      0.022      -2.640      -0.205\n",
       "num_characters_in_bio       -0.1171      0.053     -2.201      0.028      -0.221      -0.013\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.52 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  [4 pts]  Backwards Elimination\n",
    "\n",
    "Next, starting with the full model, use a backwards elimination algorithm that seeks to find the model with the lowest **AIC** score. You should fit each of these models in the algorithm with *just the training dataset*. Once the algorithm has stopped, print out the summary output of your **final model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.331365\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "no_num_follows = smf.logit('y ~ number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with number of follows slope removed 74.95943769115172\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with number of follows slope removed',no_num_follows.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.276135\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "no_num_followers = smf.logit('y ~ number_of_follows + number_of_posts + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with number of followers slope removed 64.4657256333045\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with number of followers slope removed', no_num_followers.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.125481\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "no_num_posts = smf.logit('y ~ number_of_follows + number_of_followers + number_of_words_in_name + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with number of posts slope removes 35.841371446640366\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with number of posts slope removes',no_num_posts.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.150957\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "no_num_name_words = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + num_characters_in_bio + has_a_profile_pic', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with number of words in name slope removed 40.681911322586714\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with number of words in name slope removed',no_num_name_words.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.206117\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anahi/opt/miniconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "no_num_char_bio = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + number_of_words_in_name + has_a_profile_pic', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with number of characters in bio slope removed 51.16232420711869\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with number of characters in bio slope removed',no_num_char_bio.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329550\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "no_prof_pic = smf.logit('y ~ number_of_follows + number_of_followers + number_of_posts + number_of_words_in_name + num_characters_in_bio', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for model with has a profile pic slope removed 74.61454076684927\n"
     ]
    }
   ],
   "source": [
    "print('AIC for model with has a profile pic slope removed', no_prof_pic.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    95</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    89</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 11 May 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.8186</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:27:34</td>     <th>  Log-Likelihood:    </th> <td> -11.921</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th> <td> -65.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.321e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  103.9262</td> <td> 2.29e+05</td> <td>    0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_a_profile_pic[T.yes]</th> <td>  -98.8981</td> <td> 2.29e+05</td> <td>   -0.000</td> <td> 1.000</td> <td> -4.5e+05</td> <td>  4.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_follows</th>        <td>    0.0093</td> <td>    0.003</td> <td>    3.211</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_followers</th>      <td>   -0.0284</td> <td>    0.009</td> <td>   -3.146</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_words_in_name</th>  <td>   -1.3617</td> <td>    0.606</td> <td>   -2.246</td> <td> 0.025</td> <td>   -2.550</td> <td>   -0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_characters_in_bio</th>    <td>   -0.1060</td> <td>    0.050</td> <td>   -2.141</td> <td> 0.032</td> <td>   -0.203</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.51 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   95\n",
       "Model:                          Logit   Df Residuals:                       89\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 11 May 2021   Pseudo R-squ.:                  0.8186\n",
       "Time:                        00:27:34   Log-Likelihood:                -11.921\n",
       "converged:                      False   LL-Null:                       -65.717\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.321e-21\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  103.9262   2.29e+05      0.000      1.000    -4.5e+05     4.5e+05\n",
       "has_a_profile_pic[T.yes]   -98.8981   2.29e+05     -0.000      1.000    -4.5e+05     4.5e+05\n",
       "number_of_follows            0.0093      0.003      3.211      0.001       0.004       0.015\n",
       "number_of_followers         -0.0284      0.009     -3.146      0.002      -0.046      -0.011\n",
       "number_of_words_in_name     -1.3617      0.606     -2.246      0.025      -2.550      -0.173\n",
       "num_characters_in_bio       -0.1060      0.050     -2.141      0.032      -0.203      -0.009\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.51 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_num_posts.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parsimonious Model Evaluation\n",
    "\n",
    "### 5.1.  [2 pt]  Compare the BIC score from your final model (from 4) to your full model (from 3). Use the BIC score to assess which of these models is more of a parsimonious model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full model BIC: 55.17960783224504\n"
     ]
    }
   ],
   "source": [
    "print('full model BIC:',training_model.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced model BIC: 51.16463279624361\n"
     ]
    }
   ],
   "source": [
    "print('reduced model BIC:',no_num_posts.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BIC score for the reduced model is lower, so it is more of a parsimonious model than the full model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Perform a log likelihood ratio test, where your full model (from 3) is your full model and your reduced model is your \"final model\" (from 4).\n",
    "\n",
    "#### 5.2.1.  [1.5 pt]  Set up your hypotheses for this test below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$ : The reduced model is correct\n",
    "\n",
    "\n",
    "$H_A$ : The reduced model is incorrect because at least one missing coefficient is non-zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2.  [2 pt]  Calculate the test statistic for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test stat: 0.5389018555991143\n"
     ]
    }
   ],
   "source": [
    "test_stat = -2 * (no_num_posts.llf - training_model.llf)\n",
    "print('test stat:', test_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3.  [2pt]  Calculate the p-value for this test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degrees of freedom that we use for this test is df=q=1, which represents the number of slopes that are in the full model, but not in the reduced model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46288818970651846"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "1 - chi2.cdf(test_stat, df = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4.  [1.5 pt]  Make a decision about your hypotheses using a significance level of $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "becuase the pvalue is > $\\alpha$, we fail to reject the null and say there is not sufficient evidence to suggest the alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More About Models\n",
    "\n",
    "### 6.1.  [1 pt]  Considering the six possible explanatory variables we *could* include in a logistic regression, how many possible logistic regression models could we create with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we could create 64 possible regression models with this dataset\n"
     ]
    }
   ],
   "source": [
    "print('we could create',2**6,'possible regression models with this dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.  [1.5 pt]  Which of the following logistic regression models would be *less likely* to be overfit the model (using the training data)? Explain.\n",
    "a. A model that predicts fake accounts using: number_of_followers and number_of_follows? \n",
    "\n",
    "b. A model that predicts fake accounts using: num_characters_in_bio and number_of_words_in_name? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592487\n",
      "         Iterations 7\n",
      "118.57262346255865 126.23425413736027\n"
     ]
    }
   ],
   "source": [
    "mod_a = smf.logit('y ~ number_of_followers + number_of_follows', data = df_train).fit()\n",
    "print(mod_a.aic,mod_a.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424546\n",
      "         Iterations 8\n",
      "86.66376909607207 94.3253997708737\n"
     ]
    }
   ],
   "source": [
    "mod_b = smf.logit('y~num_characters_in_bio + number_of_words_in_name',data = df_train).fit()\n",
    "print(mod_b.aic,mod_b.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model b would be less liekly to overfit the model using the trianing data set becuase it has both a lower aic and bic score, showing that the explanatory variables that are included contribute enough to log likelihood value to counterbalance the amount of slopes (which in both models is 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Testing\n",
    "\n",
    "Finally, we would like to test our \"final model\" (from 4) on the **test dataset**.\n",
    "\n",
    "### 7.1.  [2 pt]  Plot the ROC and calculate the AUC for the \"final model\" (from 4) with the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000435\n",
       "36    0.000003\n",
       "75    0.951887\n",
       "3     0.000575\n",
       "99    1.000000\n",
       "29    0.007642\n",
       "18    0.153684\n",
       "73    1.000000\n",
       "76    1.000000\n",
       "24    0.231045\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phat_test = no_num_posts.predict(exog = df_test)\n",
    "phat_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-b413a3cb2275>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['phat_test'] = phat_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_a_profile_pic</th>\n",
       "      <th>number_of_words_in_name</th>\n",
       "      <th>num_characters_in_bio</th>\n",
       "      <th>number_of_posts</th>\n",
       "      <th>number_of_followers</th>\n",
       "      <th>number_of_follows</th>\n",
       "      <th>account_type</th>\n",
       "      <th>y</th>\n",
       "      <th>phat_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>488</td>\n",
       "      <td>604</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>185</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>356</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>415</td>\n",
       "      <td>1445</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>449</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>251</td>\n",
       "      <td>223</td>\n",
       "      <td>694</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>341</td>\n",
       "      <td>2287</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>138</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>319</td>\n",
       "      <td>328</td>\n",
       "      <td>668</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>82</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>235</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>229</td>\n",
       "      <td>492</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>4239</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    has_a_profile_pic  number_of_words_in_name  num_characters_in_bio  \\\n",
       "0                 yes                        1                     30   \n",
       "36                yes                        0                     47   \n",
       "75                yes                        1                      0   \n",
       "3                 yes                        1                     76   \n",
       "99                 no                        1                    112   \n",
       "29                yes                        2                      0   \n",
       "18                yes                        2                     39   \n",
       "73                yes                        1                      0   \n",
       "76                 no                        1                      0   \n",
       "24                yes                        1                     27   \n",
       "2                 yes                        2                     82   \n",
       "13                yes                        2                     43   \n",
       "57                 no                        2                      0   \n",
       "103               yes                        1                      0   \n",
       "59                 no                        3                      0   \n",
       "9                 yes                        1                      0   \n",
       "100                no                        1                      0   \n",
       "\n",
       "     number_of_posts  number_of_followers  number_of_follows account_type  y  \\\n",
       "0                 35                  488                604         real  0   \n",
       "36                 2                  510                185         real  0   \n",
       "75                 0                   45                 64         fake  1   \n",
       "3                  6                  225                356         real  0   \n",
       "99                 4                  415               1445         fake  1   \n",
       "29                 8                  400                449         real  0   \n",
       "18               251                  223                694         real  0   \n",
       "73                 8                  341               2287         fake  1   \n",
       "76                 0                   21                 31         fake  1   \n",
       "24                28                  116                138         real  0   \n",
       "2                319                  328                668         real  0   \n",
       "13                60                  192                141         real  0   \n",
       "57                 0                   22                 82         fake  1   \n",
       "103                0                   49                235         fake  1   \n",
       "59                 0                    9                 25         fake  1   \n",
       "9                 53                  229                492         real  0   \n",
       "100                0                  926               4239         fake  1   \n",
       "\n",
       "     phat_test  \n",
       "0     0.000435  \n",
       "36    0.000003  \n",
       "75    0.951887  \n",
       "3     0.000575  \n",
       "99    1.000000  \n",
       "29    0.007642  \n",
       "18    0.153684  \n",
       "73    1.000000  \n",
       "76    1.000000  \n",
       "24    0.231045  \n",
       "2     0.000076  \n",
       "13    0.001681  \n",
       "57    1.000000  \n",
       "103   0.988565  \n",
       "59    1.000000  \n",
       "9     0.851060  \n",
       "100   1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['phat_test'] = phat_test\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "fpr,tpr,score = roc_curve(y_true = df_test['y'],y_score = df_test['phat_test'])\n",
    "\n",
    "fprs,tprs,thresholds = roc_curve(y_true = df_test['y'],y_score = df_test['phat_test'])\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_true = df_test['y'],y_score = df_test['phat_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr,tpr,auc, lw = 2):\n",
    "    plt.plot(fpr,tpr, color = 'darkorange', lw = lw,\n",
    "             label = \"ROC curve (area = \"+str(round(auc,3))+')')\n",
    "    plt.plot([0,1],[0,1], color = 'navy', lw = lw, linestyle = '--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve Mod 1')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(fpr,tpr,auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.  [1.5 pt]  How effective will this model be at classifying Instagram accounts in the *test dataset*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be efective in classifying instagram accounts in the test dataset 100% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.  [2 pt]  Finally, find a predictive probability threshold that will give you the \"best\" false positive rate and true positive rate for the *test dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold  tpr  fpr\n",
      "0        0.0  1.0  1.0\n",
      "   threshold  tpr       fpr\n",
      "0       0.01  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.02  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.03  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.04  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.05  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.06  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.07  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.08  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.09  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0        0.1  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.11  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.12  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.13  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.14  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.15  1.0  0.333333\n",
      "   threshold  tpr       fpr\n",
      "0       0.16  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.17  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.18  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.19  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0        0.2  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.21  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.22  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.23  1.0  0.222222\n",
      "   threshold  tpr       fpr\n",
      "0       0.24  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.25  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.26  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.27  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.28  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.29  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.3  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.31  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.32  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.33  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.34  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.35  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.36  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.37  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.38  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.39  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.4  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.41  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.42  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.43  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.44  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.45  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.46  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.47  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.48  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.49  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.5  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.51  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.52  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.53  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.54  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.55  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.56  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.57  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.58  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.59  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.6  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.61  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.62  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.63  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.64  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.65  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.66  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.67  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.68  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.69  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.7  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.71  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.72  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.73  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.74  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.75  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.76  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.77  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.78  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.79  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0        0.8  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.81  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.82  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.83  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.84  1.0  0.111111\n",
      "   threshold  tpr       fpr\n",
      "0       0.85  1.0  0.111111\n",
      "   threshold  tpr  fpr\n",
      "0       0.86  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.87  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.88  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.89  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0        0.9  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.91  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.92  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.93  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.94  1.0  0.0\n",
      "   threshold  tpr  fpr\n",
      "0       0.95  1.0  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.96  0.875  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.97  0.875  0.0\n",
      "   threshold    tpr  fpr\n",
      "0       0.98  0.875  0.0\n",
      "   threshold   tpr  fpr\n",
      "0       0.99  0.75  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def tpr_fpr_thresh(y, pred_prob, thresh):\n",
    "    yhat = 1*(pred_prob >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y, y_pred=yhat).ravel()\n",
    "    tpr = tp / (fn + tp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    return pd.DataFrame({'threshold':[thresh],\n",
    "                         'tpr':[tpr], \n",
    "                         'fpr':[fpr]})\n",
    "\n",
    "for thresh in np.arange(0,1,.01):\n",
    "    print(tpr_fpr_thresh(df_test['y'],df_test['phat_test'],thresh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold level between .86 and .95 would yield a false positive rate of 0 and a true positive rate of 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
